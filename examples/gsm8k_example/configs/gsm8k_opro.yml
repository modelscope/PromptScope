# use_wandb: False

basic_config:
    task_name: &task_name train # bigbench | ncbi | ... | or your own task
    search_algo: mcts # mcts | beam_search
    print_log: true
    output_path: dump
    instruction_pos: &ins_p Q_begin
    meta_prompt_type: &meta_pt both_instructions_and_exemplars

task_config:
    train_size: 4
    eval_size: 3 # data split for reward calculation
    test_size: 3 # if test_size is not 0, the optimized nodes will be tested at last.
    seed: 42 # if need to fixed shuffled dataset
    dataset_name: &dataset gsm8k # if data is downloaded
    # Note: the current supported bigbench tasks are specified by 
    # data_dir using the same task_name (bigbench), if there is not
    # specific .py class inplemented in the tasks folder.
    post_instruction: false # false: prompt + task question | true: task question + prompt

model_config:
    scorer:
        module_name: 'aio_generation'
        model_name: qwen-turbo
        clazz: 'models.llama_index_generation_model'
        max_tokens: 2000
        seed: 1234
        batch_size: &bs 1

    optim:
        module_name: 'aio_generation'
        model_name: &optim_name qwen2-72b-instruct
        clazz: 'models.llama_index_generation_model'
        max_tokens: 2000
        seed: 1234
        temperature: &temp 1
        

evolution_config:
    num_search_steps: 10
    old_instruction_score_threshold: 0.3
    extract_final_answer_by_prompting_again: False
    include_qa: False
    evaluate_in_parallel: True
    dataset_name: *dataset
    task_name: *task_name
    initial_instructions: [
#        "请一步一步地回答下面的数学题。"
        "Let's solve the problem.",
        # "",
        # "The answer is",
    ]
    instruction_pos: *ins_p
    few_shot_qa_pairs: True
    num_score_buckets: 100
    max_num_instructions: 20
    meta_prompt_type: *meta_pt
    meta_prompt_instructions_before_exemplars: True
    few_shot_selection_criteria: random
    optimizer_llm_name: *optim_name
    optimizer_llm_temperature: *temp
    num_generated_instructions_in_each_step: 8
    evaluate_generated_ins_on_few_shot: False
    num_few_shot_questions_for_instruction_refinement: 5
    evaluate_old_ins_on_few_shot: False
    eval_interval: 3
    verbose: False
    batch_size: *bs